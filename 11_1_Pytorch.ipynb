{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss, r2_score\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump</th>\n",
       "      <th>UniCell_Size</th>\n",
       "      <th>Uni_CellShape</th>\n",
       "      <th>MargAdh</th>\n",
       "      <th>SEpith</th>\n",
       "      <th>BareN</th>\n",
       "      <th>BChromatin</th>\n",
       "      <th>NoemN</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61634</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63375</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76389</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95719</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128059</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Clump  UniCell_Size  Uni_CellShape  MargAdh  SEpith  BareN  \\\n",
       "Code                                                                 \n",
       "61634       5             4              3        1       2      2   \n",
       "63375       9             1              2        6       4     10   \n",
       "76389      10             4              7        2       2      8   \n",
       "95719       6            10             10       10       8     10   \n",
       "128059      1             1              1        1       2      5   \n",
       "\n",
       "        BChromatin  NoemN  Mitoses      Class  \n",
       "Code                                           \n",
       "61634            2      3        1     Benign  \n",
       "63375            7      7        2  Malignant  \n",
       "76389            6      1        1  Malignant  \n",
       "95719            7     10        7  Malignant  \n",
       "128059           5      1        1     Benign  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = pd.read_csv(\"./Cases/Wisconsin/BreastCancer.csv\", index_col=0)\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = LabelEncoder()\n",
    "X = cancer.drop(\"Class\", axis=1)\n",
    "y = lbl.fit_transform(cancer['Class'])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=24, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=24,stratify=y)\n",
    "X_scl_trn = scaler.fit_transform(X_train) \n",
    "X_scl_tst = scaler.transform(X_test) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([489, 9])\n",
      "torch.Size([489])\n"
     ]
    }
   ],
   "source": [
    "X_torch = torch.from_numpy(X_scl_trn)\n",
    "y_torch = torch.from_numpy(y_train)\n",
    "\n",
    "\n",
    "print(X_torch.size())\n",
    "print(y_torch.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 1, 1]                10\n",
      "==========================================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 1, 1]                10\n",
       "==========================================================================================\n",
       "Total params: 10\n",
       "Trainable params: 10\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(24)\n",
    "model = nn.Sequential(nn.Linear(in_features=X_scl_trn.shape[1], out_features=1))\n",
    "\n",
    "summary(model, (1,X_scl_trn.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.9\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.9)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1763, -0.0833, -0.2833,  0.0205,  0.3107, -0.1487, -0.1085,  0.2607,\n",
      "         -0.0464]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1273], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0459],\n",
       "        [-0.2071],\n",
       "        [-0.0973]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_torch.float())\n",
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([489, 1])\n",
      "torch.Size([489, 1])\n"
     ]
    }
   ],
   "source": [
    "y_torch = y_torch.unsqueeze(1)\n",
    "print(y_torch.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss:  0.6887467503547668\n",
      "epoch:  101  loss:  0.12147819250822067\n",
      "epoch:  201  loss:  0.10393854230642319\n",
      "epoch:  301  loss:  0.09798214584589005\n",
      "epoch:  401  loss:  0.09485926479101181\n",
      "epoch:  501  loss:  0.09286675602197647\n",
      "epoch:  601  loss:  0.09145435690879822\n",
      "epoch:  701  loss:  0.09038924425840378\n",
      "epoch:  801  loss:  0.0895538181066513\n",
      "epoch:  901  loss:  0.08888058364391327\n"
     ]
    }
   ],
   "source": [
    "for epoch in np.arange(0,1000):\n",
    "       # Forward pass: Compute predicted y by passing x to the model\n",
    "       y_pred_prob = model(X_torch.float())\n",
    "\n",
    "       # Compute and print loss\n",
    "       loss = criterion(y_pred_prob, y_torch.float())\n",
    "       if epoch%100 == 0:\n",
    "          print('epoch: ', epoch+1,' loss: ', loss.item())\n",
    "\n",
    "       # Zero gradients, perform a backward pass, and update the weights.\n",
    "       optimizer.zero_grad()\n",
    "\n",
    "       # perform a backward pass (backpropagation)\n",
    "       loss.backward()\n",
    "\n",
    "       # Update the parameters\n",
    "       optimizer.step()\n",
    "#print('epoch: ', epoch+1,' loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_torch_test = torch.from_numpy(X_scl_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inferencing on test set\n",
    "lin_output = model(X_torch_test.float()) # Equivalent predict_proba / predict\n",
    "\n",
    "np_out = lin_output.detach().numpy()\n",
    "y_pred_prob = 1 / (1 + np.exp(-np_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = y_pred_prob.reshape(y_test.shape[0],) \n",
    "\n",
    "y_pred = np.where(y_pred_prob >= 0.5,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08602577466759474"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "log_loss(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1      V2      V3      V4      V5      V6      V7      V8      V9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "      V10  ...     V52     V53     V54     V55     V56     V57     V58  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "      V59     V60  Class  \n",
       "0  0.0090  0.0032      R  \n",
       "1  0.0052  0.0044      R  \n",
       "2  0.0095  0.0078      R  \n",
       "3  0.0040  0.0117      R  \n",
       "4  0.0107  0.0094      R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar = pd.read_csv(\"./Cases/Sonar/Sonar.csv\")\n",
    "sonar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = LabelEncoder()\n",
    "X = sonar.drop(\"Class\", axis=1)\n",
    "y = lbl.fit_transform(sonar['Class'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size = 0.3, random_state=24,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([145, 60])\n",
      "torch.Size([145])\n"
     ]
    }
   ],
   "source": [
    "X_torch = torch.from_numpy(X_train)\n",
    "y_torch = torch.from_numpy(y_train)\n",
    "\n",
    "\n",
    "print(X_torch.size())\n",
    "print(y_torch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 1, 1]                61\n",
      "==========================================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 1, 1]                61\n",
       "==========================================================================================\n",
       "Total params: 61\n",
       "Trainable params: 61\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(24)\n",
    "model = nn.Sequential(nn.Linear(in_features=X_train.shape[1], out_features=1))\n",
    "\n",
    "summary(model, (1,X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.1\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0683, -0.0323, -0.1097,  0.0079,  0.1203, -0.0576, -0.0420,  0.1010,\n",
      "         -0.0180, -0.0493, -0.0260,  0.0047, -0.1052, -0.0369,  0.1252, -0.0277,\n",
      "          0.1176, -0.0504, -0.0519, -0.0385, -0.1154, -0.0778,  0.0780, -0.0969,\n",
      "          0.0441,  0.1215, -0.0164,  0.0565,  0.0603, -0.0922, -0.0498, -0.0404,\n",
      "          0.1246, -0.1152,  0.0781,  0.1213,  0.1021,  0.0550,  0.0575, -0.0069,\n",
      "          0.0650,  0.1177, -0.0415,  0.1247,  0.0205, -0.0905, -0.0927,  0.0455,\n",
      "         -0.0182, -0.0569,  0.0654, -0.0681, -0.0617,  0.0241, -0.0233, -0.1089,\n",
      "         -0.0388, -0.0454, -0.0550,  0.1005]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0196], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1534],\n",
       "        [0.3342],\n",
       "        [0.0447]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_torch.float())\n",
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([145, 1])\n",
      "torch.Size([145, 1])\n"
     ]
    }
   ],
   "source": [
    "y_torch = y_torch.unsqueeze(1)\n",
    "print(y_torch.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss:  0.6839818954467773\n",
      "epoch:  101  loss:  0.6076671481132507\n",
      "epoch:  201  loss:  0.5660024881362915\n",
      "epoch:  301  loss:  0.5375736355781555\n",
      "epoch:  401  loss:  0.5169585943222046\n",
      "epoch:  501  loss:  0.50129634141922\n",
      "epoch:  601  loss:  0.4889477491378784\n",
      "epoch:  701  loss:  0.47891560196876526\n",
      "epoch:  801  loss:  0.4705631136894226\n",
      "epoch:  901  loss:  0.4634658694267273\n"
     ]
    }
   ],
   "source": [
    "for epoch in np.arange(0,1000):\n",
    "       # Forward pass: Compute predicted y by passing x to the model\n",
    "       y_pred_prob = model(X_torch.float())\n",
    "\n",
    "       # Compute and print loss\n",
    "       loss = criterion(y_pred_prob, y_torch.float())\n",
    "       if epoch%100 == 0:\n",
    "          print('epoch: ', epoch+1,' loss: ', loss.item())\n",
    "\n",
    "       # Zero gradients, perform a backward pass, and update the weights.\n",
    "       optimizer.zero_grad()\n",
    "\n",
    "       # perform a backward pass (backpropagation)\n",
    "       loss.backward()\n",
    "\n",
    "       # Update the parameters\n",
    "       optimizer.step()\n",
    "#print('epoch: ', epoch+1,' loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_torch_test = torch.from_numpy(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inferencing on test set\n",
    "lin_output = model(X_torch_test.float()) # Equivalent predict_proba / predict\n",
    "\n",
    "np_out = lin_output.detach().numpy()\n",
    "y_pred_prob = 1 / (1 + np.exp(-np_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = y_pred_prob.reshape(y_test.shape[0],) \n",
    "\n",
    "y_pred = np.where(y_pred_prob >= 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7301587301587301\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48607733017880606"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Cases/Concrete Strength/Concrete_Data.csv\")\n",
    "X = df.drop('Strength', axis=1).values\n",
    "y = df['Strength'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=24)\n",
    "X_scl_trn = scaler_X.fit_transform(X_train)\n",
    "X_scl_tst = scaler_X.transform(X_test)\n",
    "y_scl_trn = scaler_y.fit_transform(y_train.reshape(-1,1))\n",
    "y_scl_tst = scaler_y.transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([721, 8])\n",
      "torch.Size([721, 1])\n"
     ]
    }
   ],
   "source": [
    "X_torch = torch.from_numpy(X_scl_trn)\n",
    "y_torch = torch.from_numpy(y_scl_trn)\n",
    "\n",
    "\n",
    "print(X_torch.size())\n",
    "print(y_torch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 1, 1]                9\n",
      "==========================================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.9\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(24)\n",
    "model = nn.Sequential(nn.Linear(in_features=X_scl_trn.shape[1], out_features=1))\n",
    "\n",
    "summary(model, (1,X_scl_trn.shape[1]))\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.9)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1870, -0.0884, -0.3005,  0.0218,  0.3295, -0.1577, -0.1151,  0.2765]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0492], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0328],\n",
       "        [-0.2980],\n",
       "        [-0.1653]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_torch.float())\n",
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss:  0.6728695631027222\n",
      "epoch:  101  loss:  0.6345343589782715\n",
      "epoch:  201  loss:  0.627467930316925\n",
      "epoch:  301  loss:  0.624991238117218\n",
      "epoch:  401  loss:  0.623862624168396\n",
      "epoch:  501  loss:  0.6232430338859558\n",
      "epoch:  601  loss:  0.6228533387184143\n",
      "epoch:  701  loss:  0.6225841045379639\n",
      "epoch:  801  loss:  0.6223867535591125\n",
      "epoch:  901  loss:  0.6222362518310547\n"
     ]
    }
   ],
   "source": [
    "for epoch in np.arange(0,1000):\n",
    "       # Forward pass: Compute predicted y by passing x to the model\n",
    "       y_pred_prob = model(X_torch.float())\n",
    "\n",
    "       # Compute and print loss\n",
    "       loss = criterion(y_pred_prob, y_torch.float())\n",
    "       if epoch%100 == 0:\n",
    "          print('epoch: ', epoch+1,' loss: ', loss.item())\n",
    "\n",
    "       # Zero gradients, perform a backward pass, and update the weights.\n",
    "       optimizer.zero_grad()\n",
    "\n",
    "       # perform a backward pass (backpropagation)\n",
    "       loss.backward()\n",
    "\n",
    "       # Update the parameters\n",
    "       optimizer.step()\n",
    "#print('epoch: ', epoch+1,' loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_torch_test = torch.from_numpy(X_scl_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inferencing on test set\n",
    "lin_output = model(X_torch_test.float()) # Equivalent predict_proba / predict\n",
    "\n",
    "np_out = lin_output.detach().numpy()\n",
    "y_pred_prob = 1 / (1 + np.exp(-np_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = y_pred_prob.reshape(y_test.shape[0],) \n",
    "\n",
    "y_pred = np.where(y_pred_prob >= 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.685996918163576\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPA1: hɛˈloʊ haʊ ər ju təˈdeɪ\n",
      "IPA2: hallo* ənd haʊ ər ju təˈdeɪ?\n",
      "Differences:\n",
      "  h\n",
      "- ɛ\n",
      "- ˈ\n",
      "+ a\n",
      "+ l\n",
      "  l\n",
      "  o\n",
      "- ʊ\n",
      "+ *\n",
      "+  \n",
      "+ ə\n",
      "+ n\n",
      "+ d\n",
      "   \n",
      "  h\n",
      "  a\n",
      "  ʊ\n",
      "   \n",
      "  ə\n",
      "  r\n",
      "   \n",
      "  j\n",
      "  u\n",
      "   \n",
      "  t\n",
      "  ə\n",
      "  ˈ\n",
      "  d\n",
      "  e\n",
      "  ɪ\n",
      "+ ?\n"
     ]
    }
   ],
   "source": [
    "import eng_to_ipa\n",
    "from difflib import ndiff\n",
    "\n",
    "def get_ipa(text):\n",
    "    # Convert the string to IPA using eng_to_ipa library\n",
    "    ipa = eng_to_ipa.convert(text)\n",
    "    return ipa\n",
    "\n",
    "def compare_ipa(text1, text2):\n",
    "    ipa1 = get_ipa(text1)\n",
    "    ipa2 = get_ipa(text2)\n",
    "    \n",
    "    # Use ndiff to get the differences between two IPA strings\n",
    "    diff = list(ndiff(ipa1, ipa2))\n",
    "    \n",
    "    return diff\n",
    "\n",
    "# Example usage\n",
    "text1 = \"hello how are you today\"\n",
    "text2 = \"hallo and how are you today?\"\n",
    "\n",
    "diff = compare_ipa(text1, text2)\n",
    "\n",
    "# Print the IPA transcriptions and differences\n",
    "print(f\"IPA1: {get_ipa(text1)}\")\n",
    "print(f\"IPA2: {get_ipa(text2)}\")\n",
    "print(\"Differences:\")\n",
    "print(\"\\n\".join(diff))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
